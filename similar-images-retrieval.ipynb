{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar Images Retrieval with Color Clusters\n",
    "Given an image, this script will retrieve the K most color-similar images out of an image collection.\n",
    "\n",
    "For the demonstration of the algorithm a Pokemon dataset has been extracted. This dataset contains for each Pokemon it's weight, height, type and sprite. Furthermore, we investigate if there is a correlation between the colors of a Pokemon and it's type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "sprites_path = 'sprites/'\n",
    "data_json = 'data.json'\n",
    "data = {}\n",
    "\n",
    "def sprite_file(name):\n",
    "    return sprites_path + name + '.png'\n",
    "\n",
    "\n",
    "def download_file(url, name):\n",
    "    r = requests.get(url)\n",
    "    with open(name, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    if not os.path.exists(sprites_path):\n",
    "        os.makedirs(sprites_path)\n",
    "    j = requests.get('https://pokeapi.co/api/v2/pokemon?limit=-1').json()\n",
    "    for res in j['results']:\n",
    "        name = res['name']\n",
    "        url = res['url']\n",
    "        p = requests.get(url).json()\n",
    "        height = p['height']\n",
    "        weight = p['weight']\n",
    "        types = [t['type']['name'] for t in p['types']]\n",
    "        sprite = p['sprites']['front_default']\n",
    "        if sprite:\n",
    "            fname = sprite_file(name)\n",
    "            if not os.path.exists(fname):\n",
    "                download_file(sprite, fname)\n",
    "            data[name] = [height, weight, types]\n",
    "        else:\n",
    "            print('Missing', name)\n",
    "\n",
    "\n",
    "def save_data(data, fname):\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write(json.dumps(data))\n",
    "\n",
    "\n",
    "def load_data(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        source = f.read()\n",
    "        data = json.loads(source)\n",
    "    return data\n",
    "\n",
    "\n",
    "if os.path.exists(data_json):\n",
    "    print('Loading data')\n",
    "    data = load_data(data_json)\n",
    "else:\n",
    "    print('Downloading data')\n",
    "    download_data()\n",
    "    save_data(data, data_json)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sample visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_sample(rows, cols):\n",
    "    print('Total size:', len(data))\n",
    "    _, axs = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "    axs = axs.flatten()\n",
    "    # Display part of the pokemon dataset\n",
    "    for (name, value), ax in zip(data.items(), axs):\n",
    "        print(name, value)\n",
    "        im = plt.imread(sprite_file(name))\n",
    "        ax.axis('off')\n",
    "        ax.imshow(im)\n",
    "\n",
    "\n",
    "display_sample(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering on pixels\n",
    "\n",
    "For every pokemon image we are retrieving its M most frequent colors by performing a clustering procedure (DBSCAN) on its pixels. Then, M number of clusters will be created each one of them corresponding to a most frequent color. \n",
    "\n",
    "We are giving DBSCAN a small radius-value and a big number of components per cluster so that it finds very small, compact clusters representing frequent colors. All the rest points-colors are considered to be noise. We take the core-components returned by DBSCAN for each cluster and we define their mean value as the representatives of those clusters.\n",
    "From now on, we are using those representatives to \"represent\" the image.\n",
    "We create (once) a new .json file named \"pokemon4.json\" which contains all of the new 'representations' of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing all the transparent pixels - Transforming RGBA to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_pixels(im):\n",
    "    im = im.reshape(-1, 4)\n",
    "    im = im[im[:,3] > 0]\n",
    "    im = np.delete(im, 3, 1)\n",
    "#     pixels = (im * 255).astype(np.uint8)\n",
    "    return im\n",
    "\n",
    "pixel_dict = {}\n",
    "for name in data:\n",
    "    im = plt.imread(sprite_file(name))\n",
    "    pixel_dict[name] = get_pixels(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color cluster the image collection\n",
    "The following block creates a new .json file in which the representatives of the images get stored. \n",
    "\n",
    "This is another where the clustering takes place. It is time consuming so it is reasonable to cache is.\n",
    "If the \"extracted_data.json\" file does not exist in the project folder this code is executed in order to create it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "\n",
    "extracted_json = 'extracted_data.json'\n",
    "extracted_colors = {}\n",
    "k = 2\n",
    "\n",
    "def KMeans_estimator(pixels):\n",
    "    est = KMeans(n_clusters=k+1)\n",
    "    est.fit(pixels)\n",
    "    _, counts = np.unique(est.labels_, return_counts=True)\n",
    "    idx = np.argsort(counts)\n",
    "    centers = est.cluster_centers_[idx]\n",
    "    centers = np.delete(centers, np.argmin(np.sum(centers, axis=1)), axis=0)\n",
    "    return est, centers\n",
    "\n",
    "def extract_data(pixels):\n",
    "    est = KMeans(n_clusters=k+1)\n",
    "    est.fit(pixels)\n",
    "    _, counts = np.unique(est.labels_, return_counts=True)\n",
    "    idx = np.argsort(counts)\n",
    "    centers = est.cluster_centers_[idx]\n",
    "    centers = np.delete(centers, np.argmin(np.sum(centers, axis=1)), axis=0)\n",
    "    return np.flip(centers, 0)\n",
    "\n",
    "if os.path.exists(extracted_json):\n",
    "    print('Loading extracted data')\n",
    "    extracted_colors = load_data(extracted_json)\n",
    "else:\n",
    "    print('Extracting data')\n",
    "    for name, pixels in pixel_dict.items():\n",
    "        extracted_colors[name] = extract_data(pixels).tolist()\n",
    "    save_data(extracted_colors, extracted_json)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Clusterings\n",
    "Below, we can depict the clustering that is produced from the images of some given pokemons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def display_colors(name):\n",
    "    pixels = pixel_dict[name]\n",
    "    a = int(math.sqrt(pixels.size//3))\n",
    "    colors = pixels[:(a*a)]\n",
    "    colors = colors.reshape((a,a,3))\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    im = plt.imread(sprite_file(name))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(im)\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(colors)\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    colors = np.array(sorted(pixels, key=lambda tup: -tup[0]*255*255 -tup[1]*255 -tup[2]))\n",
    "    colors = colors[:(a*a)]\n",
    "    colors = colors.reshape((a,a,3))\n",
    "    ax.axis('off')\n",
    "    ax.imshow(colors)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    colors = extracted_colors[name]\n",
    "    for i, c in enumerate(colors):\n",
    "        ax = fig.add_subplot(1, k, i+1)\n",
    "        im = [[c] * 16]*16\n",
    "        ax.axis('off')\n",
    "        ax.imshow(im)\n",
    "    plt.show()\n",
    "\n",
    "# c=labels.astype(np.float)\n",
    "for name, pixels in pixel_dict.items():\n",
    "    display_colors(name)\n",
    "    colors = np.array(extracted_colors[name])\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = fig.add_subplot(121, projection='3d')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    ax.scatter(pixels[:,0], pixels[:,1], pixels[:,2], c=pixels)\n",
    "    ax = fig.add_subplot(122, projection='3d')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    ax.scatter(colors[:,0], colors[:,1], colors[:,2], c=colors)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a good k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, pixels in pixel_dict.items():\n",
    "    inertia = []\n",
    "    K = range(1,7)\n",
    "    for y in K:\n",
    "        km = KMeans(n_clusters=y)\n",
    "        km = km.fit(pixels)\n",
    "        inertia.append(km.inertia_)\n",
    "    inertia = np.array(inertia)/inertia[0]\n",
    "    plt.plot(K, inertia)\n",
    "    break\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve K most similar Images\n",
    "\n",
    "Now, for a given image specified by its file-name (e.g. \"0001.png\") we compute all the eucledian distances between that image and the rest of them (based on their new representations), and then print the images corresponding to the K smallest distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Computes the minimum distance between two images\n",
    "def color_distance(a, b):\n",
    "#     na = [c*(k-i+1) for i, c in enumerate(a)]\n",
    "#     nb = [c*(k-i+1) for i, c in enumerate(b)]\n",
    "#     return distance.euclidean(np.sum(na, axis=0), np.sum(nb, axis=0))\n",
    "# \n",
    "#     return distance.euclidean(np.sum(a, axis=0), np.sum(b, axis=0))\n",
    "    it = itertools.permutations(b)\n",
    "    return np.min([np.mean([distance.euclidean(x,y) for (x, y) in zip(a, permutation)]) for permutation in it])\n",
    "\n",
    "\n",
    "def retrieve_similar_images(name, rows, cols):\n",
    "    distances = []\n",
    "    colors = extracted_colors[name]\n",
    "    for key, values in extracted_colors.items():\n",
    "        if key != name: \n",
    "            dist = color_distance(colors, values)\n",
    "            distances.append([key, dist])\n",
    "    distances = sorted(distances, key=lambda x: x[1])\n",
    "    # Retrieve the K most similar images\n",
    "    k = rows * cols\n",
    "    similar_K = distances[:k]\n",
    "    display_colors(name)\n",
    "    # print(similar_K)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    for i, f in enumerate(similar_K):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.axis('off')\n",
    "        im = plt.imread(sprite_file(f[0]))\n",
    "        ax.imshow(im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulbasaur\n",
    "retrieve_similar_images('bulbasaur', 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charmander\n",
    "retrieve_similar_images('charmander', 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squirtle\n",
    "retrieve_similar_images('squirtle', 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pikachu\n",
    "retrieve_similar_images('pikachu', 3, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
